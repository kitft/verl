# Tiny NLA GRPO configuration for testing
# Inherits from nla_grpo_trainer.yaml with tiny model settings

# Inherit from base PPO trainer and customize for NLA tiny testing
defaults:
  # Include base PPO defaults (actor, critic, data, etc.)
  - ppo_trainer
  # Override with our settings last
  - _self_

# Override trainer settings for NLA tiny testing
trainer:
  # Project and experiment names
  project_name: nla_experiments
  experiment_name: grpo_tiny_test

  # Minimal training for quick testing
  total_training_steps: 10
  save_freq: 10
  test_freq: 5

  # Single node/GPU for testing
  nnodes: 1
  n_gpus_per_node: 1

  # Use console logging only for testing
  logger: ["console"]

# Override algorithm for GRPO
algorithm:
  # Use GRPO advantage estimator
  adv_estimator: grpo
  # GRPO typically uses different normalization
  norm_adv_by_std_in_grpo: true
  # Disable KL penalties for NLA (we use reconstruction loss)
  use_kl_in_reward: false

# Override model paths for tiny model
actor_rollout_ref:
  model:
    path: google/gemma-2-2b-it
    tokenizer_path: google/gemma-2-2b-it

  # Actor FSDP configuration
  actor:
    strategy: fsdp2
    ppo_micro_batch_size_per_gpu: 2  # Required for actor training
    fsdp_config:
      model_dtype: bf16  # TODO: Flash Attention warning about dtype - may need to address later
      mixed_precision:
        param_dtype: bf16
        reduce_dtype: fp32
        buffer_dtype: fp32

  # Reduce rollout batch size for testing
  rollout:
    name: nla_sglang  # Use NLA-specific SGLang rollout
    mode: sync  # Use sync mode for simpler setup
    tensor_model_parallel_size: 1
    disable_radix_cache: true

    # Generation parameters
    response_length: 50  # Max tokens to generate
    temperature: 0.7  # Sampling temperature
    do_sample: true  # Enable sampling

# Tiny model critic settings
critic:
  enable: true  # Explicitly enable critic for NLA GRPO
  strategy: fsdp2
  model:
    path: google/gemma-2-2b-it
    fsdp_config:
      model_dtype: bf16  # TODO: Flash Attention warning about dtype - may need to address later
      mixed_precision:
        param_dtype: bf16
        reduce_dtype: fp32
        buffer_dtype: fp32

  # Set PPO micro batch size for critic training
  ppo_micro_batch_size_per_gpu: 2

# NLA settings for tiny model
nla:
  # Enable NLA datasets
  use_nla_datasets: true

  # activation_dim will be auto-determined from model's hidden_size
  # No need to specify it explicitly

  # Injection settings for activation vectors
  injection:
    mode: replace  # Replace embedding at injection position
    layer_indices: [0]  # Not used for embedding injection, kept for compatibility
    injection_token: null  # Auto-detect special token or use position 1

  # Reduce GRPO settings for testing
  grpo:
    num_trajectories_per_prompt: 2  # Only 2 responses per prompt for speed
    critic_train_epochs: 1

# Test data settings
data:
  # Use test datasets
  train_files:
    - data/testing/test_nla_dataset_tiny.parquet

  val_files:
    - data/testing/test_nla_dataset.parquet

  # Very small batches for testing
  train_batch_size: 2
  val_batch_size: 2

  # No parallel workers for testing
  num_workers: 0
  valid_num_workers: 0
  dataloader_num_workers: 0

# Ray settings for testing
ray_kwargs:
  ray_init:
    num_cpus: 4
    num_gpus: 1  # GPU testing

    runtime_env:
      env_vars:
        TOKENIZERS_PARALLELISM: "false"
        NCCL_DEBUG: "WARN"

      # Exclude large files from packaging
      excludes:
        - "*.whl"
        - "*.whl.1"
        - ".git/"
        - "__pycache__/"
        - "*.pyc"
        - ".venv/"
        - "data/testing/*.parquet"
        - "*.parquet"
        - "flashinfer_python*"
        - "flash_attn*"