# NLA SFT configuration - Full-scale 0.5B model training
# Inherits from sft_trainer and overrides for full NLA training

defaults:
  - sft_trainer
  - _self_

# Data configuration - larger batches for full training
data:
  train_batch_size: 256
  micro_batch_size_per_gpu: 64
  train_files: data/small/sft/train_nla_sft_dataset_fineweb_layer10.parquet
  val_files: data/small/sft/val_nla_sft_dataset_fineweb_layer10.parquet

  # Dataset keys
  prompt_key: prompt  # Use 'prompt' (message array) not 'prompt_text' (pre-formatted string)
  response_key: response

  # Custom NLA dataset class
  custom_cls:
    path: verl.nla.data.nla_sft_dataset
    name: NLASFTDataset

  # activation_dim now determined dynamically from model config

  max_length: 256  # Longer sequences for full training
  truncation: error
  use_shm: false

# Model configuration - 0.5B Qwen model
model:
  partial_pretrain: Qwen/Qwen2.5-0.5B-Instruct
  trust_remote_code: true
  enable_gradient_checkpointing: true  # Enable for memory efficiency
  use_liger: false
  strategy: fsdp2

  fsdp_config:
    model_dtype: bf16
    wrap_policy:
      min_num_params: 0
    cpu_offload: false
    offload_params: false

# Optimizer configuration - full training settings
optim:
  lr: 5e-5  # Lower learning rate for full training
  betas: [0.9, 0.999]
  weight_decay: 0.01
  warmup_steps_ratio: 0.05  # 5% warmup for longer training
  clip_grad: 1.0
  lr_scheduler: cosine

# Trainer configuration - full scale training
trainer:
  default_local_dir: checkpoints/nla_sft_full
  project_name: null  # Auto-filled from model name + train_mode when unset
  experiment_name: null
  total_epochs: 1  # Single epoch baseline; increase as needed for longer runs
  total_training_steps: null  # Let it run for full epochs
  logger: ["console", "wandb"]
  seed: 42
  save_freq: -1  # Only save at end of training
  test_freq: 100  # Validate more frequently
  nnodes: 1
  n_gpus_per_node: 1
  device: cuda
  resume_mode: disable  # Start fresh by default; override to auto for resumable runs

  checkpoint:
    save_contents: ["model", "optimizer", "extra", "hf_model"]  # Include HF model for RL training
    load_contents: ["model", "optimizer", "extra"]

# Engine configuration (for non-FSDP trainer)
engine:
  strategy: fsdp2

# NLA-specific configuration
nla:
  # activation_dim now determined dynamically from model's hidden_size
  train_mode: actor  # "actor" or "critic"

  # Injection configuration for actor
  injection:
    mode: replace
    layer_indices: [0]
    projection_dim: null
    injection_token: null  # Let system auto-select

  # Critic model configuration
  critic:
    model_path: Qwen/Qwen2.5-0.5B-Instruct  # Should be same as actor model
    pooling: last
    dropout: 0.1
    projection_layers: 2

  # Training settings
  critic_lr: 2e-5  # Lower learning rate for full training
  critic_epochs: 3  # More epochs for critic
