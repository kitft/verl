# @package _global_

defaults:
  - /nla_grpo_full
  - _self_

actor_rollout_ref:
  model:
    path: Qwen/Qwen2.5-0.5B-Instruct
    trust_remote_code: true
    enable_gradient_checkpointing: false
    use_shm: false
  actor:
    ppo_micro_batch_size_per_gpu: 2
    optim:
      lr: 1e-5
      weight_decay: 0.01
      lr_warmup_steps: 50

critic:
  ppo_micro_batch_size_per_gpu: 2
  model:
    path: Qwen/Qwen2.5-0.5B-Instruct
    trust_remote_code: true
  optim:
    lr: 5e-5
    weight_decay: 0.01
    lr_warmup_steps: 50

trainer:
  total_training_steps: 1000
  ppo_mini_batch_size: 8
  ppo_epochs: 2
  steps_per_update: 2
  project_name: nla-rl
  experiment_name: qwen-small-canonical
  logger: ["console", "wandb"]
  resume_mode: disable
  
ray_kwargs:
  ray_init:
    num_cpus: 8
    num_gpus: 1
  resource_pool:
    actor_rollout:
      num_gpus: 1
      num_cpus: 4
    critic:
      num_gpus: 0
      num_cpus: 4

nla:
  injection:
    mode: replace
    layer_indices: [0]
    projection_dim: null
    injection_token: null

engine_kwargs:
  sglang:
    # attention_chunk_size: 0  # Uncomment to disable SWA if encountering NoneType errors with input_embeds

# Dataset paths generated by scripts/run_qwen_tiny_pipeline.py
# (use the canonical layer10 activations by default).
data:
  train_files:
    - /workspace-vast/kitf/nla/data/generated/rl_train_fineweb10bt_qwen_small_layer10.parquet
  val_files:
    - /workspace-vast/kitf/nla/data/generated/rl_val_fineweb10bt_qwen_small_layer10.parquet
