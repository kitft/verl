# NLA SFT configuration - Tiny model for testing
# Inherits from sft_trainer and overrides for NLA

defaults:
  - sft_trainer
  - _self_

# Data configuration
data:
  train_batch_size: 8
  micro_batch_size_per_gpu: 2
  train_files: data/testing/sft/train_nla_sft_dataset_fineweb_layer10.parquet
  val_files: data/testing/sft/val_nla_sft_dataset_fineweb_layer10.parquet

  # Dataset keys
  prompt_key: prompt_text
  response_key: response

  # Custom NLA dataset class
  custom_cls:
    path: verl.nla.data.nla_sft_dataset
    name: NLASFTDataset

  # activation_dim now determined dynamically from model config

  max_length: 512
  truncation: error
  use_shm: false

# Model configuration
model:
  partial_pretrain: Qwen/Qwen2.5-0.5B-Instruct
  trust_remote_code: true
  enable_gradient_checkpointing: false
  use_liger: false
  strategy: fsdp2

  fsdp_config:
    model_dtype: bf16
    wrap_policy:
      min_num_params: 0
    cpu_offload: false
    offload_params: false

# Optimizer configuration
optim:
  lr: 1e-4
  betas: [0.9, 0.999]
  weight_decay: 0.01
  warmup_steps_ratio: 0.1
  clip_grad: 1.0
  lr_scheduler: cosine

# Trainer configuration
trainer:
  default_local_dir: checkpoints/nla_sft_tiny
  project_name: null  # Auto-filled from model name + train_mode when unset
  experiment_name: null
  total_epochs: 1
  total_training_steps: 10
  logger: ["console", "wandb"]
  seed: 42
  save_freq: -1  # Only save at end of training
  test_freq: 10
  nnodes: 1
  n_gpus_per_node: 1
  device: cuda
  resume_mode: disable

  checkpoint:
    save_contents: ["model", "optimizer", "extra", "hf_model"]  # Include HF model for RL training
    load_contents: ["model", "optimizer", "extra"]

# Engine configuration (for non-FSDP trainer)
engine:
  strategy: fsdp2

# NLA-specific configuration
nla:
  # activation_dim now determined dynamically from model's hidden_size
  train_mode: actor  # "actor" or "critic"

  # Injection configuration for actor
  injection:
    mode: replace
    layer_indices: [0]
    projection_dim: null
    injection_token: null  # Let system auto-select

  # Critic model configuration
  critic:
    model_path: Qwen/Qwen2.5-0.5B-Instruct  # Should be same as actor model
    pooling: last
    dropout: 0.1
    projection_layers: 2

  # Training settings
  critic_lr: 5e-4
  critic_epochs: 1
