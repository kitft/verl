defaults:
  - _self_

mode: rl  # "rl" or "sft"

dataset:
  name: null
  config_name: null
  split: train
  input_parquet: null
  max_samples: null
  chat_column: null
  text_column: null
  user_role: user
  system_prompt: null
  add_generation_prompt: true
  expect_chat: false

model:
  name: google/gemma-2-2b-it
  trust_remote_code: true
  layer_index: -1
  use_fp16: false

sampling:
  total_activations: 256
  activations_per_sample: 1
  max_length: 1024

output:
  path: data/generated/activation_dataset.parquet
  overwrite: false
  include_layer_suffix: true
  injection_token: null

prompt:
  default_role: user
  add_generation_prompt: true
  chat_template: null
  messages:
    - role: user
      template: |
        Explain the following text {injection_token}


response:
  template: "{source}"

seed: 42
